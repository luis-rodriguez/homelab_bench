name: Shell Test Suite

on:
  pull_request:
    branches: [ "main", "master" ]
  push:
    branches: [ "main", "master" ]
  workflow_dispatch:

# Restrict permissions of GITHUB_TOKEN for security
permissions:
  contents: read

# Cancel in-progress runs for the same PR/branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  # Override results directory for CI
  RESULTS_BASE_DIR: ${{ github.workspace }}/test_results
  # Prevent interactive prompts
  DEBIAN_FRONTEND: noninteractive
  TERM: dumb

jobs:
  # ============================================================================
  # PHASE 1: CODE QUALITY & STATIC ANALYSIS
  # ============================================================================
  
  shellcheck:
    name: ShellCheck (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup shell environment
        uses: ./.github/actions/setup-shell-environment
        with:
          install-shellcheck: 'true'
          make-executable: 'false'

      - name: Run shellcheck on all scripts
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::ShellCheck Analysis"
          
          # Enable extended globbing for recursive patterns
          shopt -s globstar 2>/dev/null || true
          
          # Run shellcheck with source following enabled
          # -x: follow source statements
          # --severity=warning: show warnings and above
          # --format=gcc: parseable format for CI
          
          EXIT_CODE=0
          shellcheck -x --severity=warning --format=gcc \
            bin/**/*.sh bin/*.sh \
            scripts/**/*.sh scripts/*.sh \
            tests/**/*.sh tests/*.sh \
            2>&1 | tee shellcheck-results.txt || EXIT_CODE=$?
          
          echo "::endgroup::"
          
          # Show summary
          if [[ $EXIT_CODE -eq 0 ]]; then
            echo "✓ ShellCheck passed with no warnings or errors"
          else
            echo "::error::ShellCheck found issues (exit code: $EXIT_CODE)"
            echo "Review the shellcheck-results.txt artifact for details"
            exit $EXIT_CODE
          fi

      - name: Upload shellcheck results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: shellcheck-results-${{ matrix.os }}
          path: shellcheck-results.txt
          retention-days: 7

  bash-syntax:
    name: Bash Syntax Check (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup shell environment
        uses: ./.github/actions/setup-shell-environment
        with:
          install-shellcheck: 'false'
          make-executable: 'true'

      - name: Verify bash syntax (bash -n)
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Bash Syntax Validation"
          
          FAILED=0
          while IFS= read -r -d '' script; do
            echo "Checking: $script"
            if ! bash -n "$script"; then
              echo "::error file=$script::Syntax error in $script"
              FAILED=1
            fi
          done < <(find . -type f -name '*.sh' -not -path './.git/*' -print0)
          
          echo "::endgroup::"
          
          if [[ $FAILED -eq 0 ]]; then
            echo "✓ All scripts have valid bash syntax"
          else
            echo "::error::One or more scripts have syntax errors"
            exit 1
          fi

  # ============================================================================
  # PHASE 2: FUNCTIONAL TESTS
  # ============================================================================

  smoke-tests:
    name: Smoke Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    needs: [bash-syntax]
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup shell environment
        uses: ./.github/actions/setup-shell-environment
        with:
          install-shellcheck: 'false'
          make-executable: 'true'

      - name: Create results directory
        shell: bash
        run: |
          mkdir -p "$RESULTS_BASE_DIR/logs"
          echo "Results directory: $RESULTS_BASE_DIR"

      - name: Run homelab_benchmark.sh dry-run
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Homelab Benchmark Dry-Run"
          
          EXIT_CODE=0
          bin/homelab_benchmark.sh --dry-run localhost \
            </dev/null 2>&1 | tee "$RESULTS_BASE_DIR/logs/smoke_homelab.log" || EXIT_CODE=$?
          
          echo "::endgroup::"
          
          if [[ $EXIT_CODE -eq 0 ]]; then
            echo "✓ Homelab benchmark dry-run completed successfully"
          else
            echo "::warning::Homelab benchmark dry-run exited with code $EXIT_CODE (expected in dry-run mode)"
            # Dry-run may fail SSH connection but that's expected
            # Only fail if the script itself has errors
            if grep -q "not found\|Permission denied\|No such file" "$RESULTS_BASE_DIR/logs/smoke_homelab.log"; then
              echo "::error::Script has critical errors"
              exit 1
            fi
          fi

      - name: Run local_benchmark.sh dry-run
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Local Benchmark Dry-Run"
          
          EXIT_CODE=0
          bin/local_benchmark.sh --dry-run \
            </dev/null 2>&1 | tee "$RESULTS_BASE_DIR/logs/smoke_local.log" || EXIT_CODE=$?
          
          echo "::endgroup::"
          
          if [[ $EXIT_CODE -eq 0 ]]; then
            echo "✓ Local benchmark dry-run completed successfully"
          else
            echo "::warning::Local benchmark dry-run exited with code $EXIT_CODE"
            # Check for critical errors
            if grep -q "not found\|Permission denied\|No such file" "$RESULTS_BASE_DIR/logs/smoke_local.log"; then
              echo "::error::Script has critical errors"
              exit 1
            fi
          fi

      - name: Verify results structure
        shell: bash
        run: |
          echo "::group::Results Directory Structure"
          if [[ -d "$RESULTS_BASE_DIR" ]]; then
            find "$RESULTS_BASE_DIR" -type f -o -type d | head -20
            echo "✓ Results directory created"
          else
            echo "::warning::Results directory not created (may be expected in dry-run)"
          fi
          echo "::endgroup::"

      - name: Upload smoke test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-test-logs-${{ matrix.os }}
          path: ${{ env.RESULTS_BASE_DIR }}/logs/
          retention-days: 7

  # ============================================================================
  # PHASE 3: WORKFLOW VALIDATION
  # ============================================================================

  workflow-validation:
    name: Workflow Validation
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup shell environment
        uses: ./.github/actions/setup-shell-environment
        with:
          install-shellcheck: 'false'
          make-executable: 'true'

      - name: Check for deprecated actions
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Scanning for deprecated GitHub Actions"
          
          scripts/check-workflows.sh
          
          echo "::endgroup::"
          echo "✓ No deprecated actions found"

      - name: Validate workflow YAML syntax
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Validating Workflow YAML Syntax"
          
          # Check all workflow files are valid YAML
          FAILED=0
          while IFS= read -r -d '' workflow; do
            echo "Checking: $workflow"
            if ! python3 -c "import yaml; yaml.safe_load(open('$workflow'))" 2>/dev/null; then
              echo "::error file=$workflow::Invalid YAML in $workflow"
              FAILED=1
            fi
          done < <(find .github/workflows -name '*.yml' -print0)
          
          echo "::endgroup::"
          
          if [[ $FAILED -eq 0 ]]; then
            echo "✓ All workflow files have valid YAML syntax"
          else
            echo "::error::One or more workflow files have invalid YAML"
            exit 1
          fi

  # ============================================================================
  # PHASE 4: INTEGRATION TEST (Optional Full Run)
  # ============================================================================

  integration-test:
    name: Integration Test (Ubuntu)
    runs-on: ubuntu-latest
    needs: [shellcheck, smoke-tests]
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup shell environment
        uses: ./.github/actions/setup-shell-environment
        with:
          install-shellcheck: 'true'
          make-executable: 'true'

      - name: Install benchmark dependencies
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Installing Benchmark Tools"
          
          # Install common benchmarking tools available in CI
          sudo apt-get update -qq
          sudo apt-get install -y \
            sysbench \
            fio \
            iperf3 \
            stress-ng \
            2>/dev/null || echo "Some tools may not be available"
          
          echo "::endgroup::"

      - name: Run local benchmark with real tests (limited)
        shell: bash
        run: |
          set -euo pipefail
          echo "::group::Running Limited Local Benchmark"
          
          # Run actual benchmark but with minimal/fast settings
          # This validates the full pipeline works end-to-end
          SUDO_NOPASS=false bin/local_benchmark.sh \
            </dev/null 2>&1 | tee integration-test.log || true
          
          echo "::endgroup::"
          echo "✓ Integration test completed (check logs for details)"

      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            integration-test.log
            ${{ env.RESULTS_BASE_DIR }}/
          retention-days: 7

  # ============================================================================
  # FINAL: TEST SUMMARY
  # ============================================================================

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [shellcheck, bash-syntax, smoke-tests, workflow-validation]
    if: always()
    
    steps:
      - name: Check test results
        shell: bash
        run: |
          echo "::group::Test Suite Summary"
          echo "ShellCheck: ${{ needs.shellcheck.result }}"
          echo "Bash Syntax: ${{ needs.bash-syntax.result }}"
          echo "Smoke Tests: ${{ needs.smoke-tests.result }}"
          echo "Workflow Validation: ${{ needs.workflow-validation.result }}"
          echo "::endgroup::"
          
          # Fail if any required test failed
          if [[ "${{ needs.shellcheck.result }}" != "success" ]] || \
             [[ "${{ needs.bash-syntax.result }}" != "success" ]] || \
             [[ "${{ needs.smoke-tests.result }}" != "success" ]] || \
             [[ "${{ needs.workflow-validation.result }}" != "success" ]]; then
            echo "::error::One or more test suites failed"
            exit 1
          fi
          
          echo "✓ All test suites passed successfully"
